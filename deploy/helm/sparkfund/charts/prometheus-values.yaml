# Prometheus Helm chart values for SparkFund
# This file configures the kube-prometheus-stack chart

# Global settings
global:
  # Evaluation interval for rules
  evaluation_interval: 1m
  # Scrape interval for metrics
  scrape_interval: 30s
  # Scrape timeout for metrics
  scrape_timeout: 10s

# Prometheus Operator configuration
prometheusOperator:
  # Enable the Prometheus Operator
  enabled: true
  
  # Resources for the Prometheus Operator
  resources:
    limits:
      cpu: 200m
      memory: 256Mi
    requests:
      cpu: 100m
      memory: 128Mi
  
  # Node affinity for the Prometheus Operator
  nodeAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        preference:
          matchExpressions:
            - key: node-role.kubernetes.io/control-plane
              operator: DoesNotExist

# Prometheus configuration
prometheus:
  # Enable Prometheus
  enabled: true
  
  # Prometheus spec
  prometheusSpec:
    # Retention period for metrics
    retention: 15d
    
    # Resources for Prometheus
    resources:
      limits:
        cpu: 1000m
        memory: 2Gi
      requests:
        cpu: 500m
        memory: 1Gi
    
    # Storage for Prometheus
    storageSpec:
      volumeClaimTemplate:
        spec:
          storageClassName: standard
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 50Gi
    
    # Additional scrape configurations
    additionalScrapeConfigs:
      # Scrape configuration for Istio
      - job_name: 'istio-mesh'
        kubernetes_sd_configs:
          - role: endpoints
            namespaces:
              names:
                - istio-system
        relabel_configs:
          - source_labels: [__meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
            action: keep
            regex: istio-telemetry;prometheus
      
      # Scrape configuration for Envoy stats
      - job_name: 'envoy-stats'
        metrics_path: /stats/prometheus
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_container_port_name]
            action: keep
            regex: '.*-envoy-prom'
      
      # Scrape configuration for Vault
      - job_name: 'vault'
        metrics_path: /v1/sys/metrics
        params:
          format: ['prometheus']
        scheme: http
        kubernetes_sd_configs:
          - role: endpoints
            namespaces:
              names:
                - vault
        relabel_configs:
          - source_labels: [__meta_kubernetes_service_name]
            action: keep
            regex: vault
    
    # External labels
    externalLabels:
      cluster: sparkfund
    
    # Enable remote write
    remoteWrite:
      - url: "http://thanos-receive.monitoring:19291/api/v1/receive"
    
    # Enable Thanos sidecar
    thanos:
      image: quay.io/thanos/thanos:v0.30.2
      version: v0.30.2
      objectStorageConfig:
        key: thanos.yaml
        name: thanos-objstore-config

# Alertmanager configuration
alertmanager:
  # Enable Alertmanager
  enabled: true
  
  # Alertmanager spec
  alertmanagerSpec:
    # Storage for Alertmanager
    storage:
      volumeClaimTemplate:
        spec:
          storageClassName: standard
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 10Gi
    
    # Resources for Alertmanager
    resources:
      limits:
        cpu: 200m
        memory: 256Mi
      requests:
        cpu: 100m
        memory: 128Mi
  
  # Alertmanager configuration
  config:
    global:
      resolve_timeout: 5m
      slack_api_url: 'https://hooks.slack.com/services/T00000000/B00000000/XXXXXXXXXXXXXXXXXXXXXXXX'
    
    route:
      group_by: ['job', 'alertname', 'severity']
      group_wait: 30s
      group_interval: 5m
      repeat_interval: 12h
      receiver: 'slack-notifications'
      routes:
        - match:
            severity: critical
          receiver: 'slack-critical'
          continue: true
        - match:
            severity: warning
          receiver: 'slack-warnings'
          continue: true
        - match:
            severity: info
          receiver: 'slack-info'
    
    receivers:
      - name: 'slack-notifications'
        slack_configs:
          - channel: '#monitoring'
            send_resolved: true
            title: '[{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}] Monitoring Alert'
            text: >-
              {{ range .Alerts }}
                *Alert:* {{ .Annotations.summary }}
                *Description:* {{ .Annotations.description }}
                *Severity:* {{ .Labels.severity }}
                *Details:*
                {{ range .Labels.SortedPairs }} • *{{ .Name }}:* {{ .Value }}
                {{ end }}
              {{ end }}
      
      - name: 'slack-critical'
        slack_configs:
          - channel: '#alerts-critical'
            send_resolved: true
            title: '[{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}] Critical Alert'
            text: >-
              {{ range .Alerts }}
                *Alert:* {{ .Annotations.summary }}
                *Description:* {{ .Annotations.description }}
                *Severity:* {{ .Labels.severity }}
                *Details:*
                {{ range .Labels.SortedPairs }} • *{{ .Name }}:* {{ .Value }}
                {{ end }}
              {{ end }}
      
      - name: 'slack-warnings'
        slack_configs:
          - channel: '#alerts-warnings'
            send_resolved: true
            title: '[{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}] Warning Alert'
            text: >-
              {{ range .Alerts }}
                *Alert:* {{ .Annotations.summary }}
                *Description:* {{ .Annotations.description }}
                *Severity:* {{ .Labels.severity }}
                *Details:*
                {{ range .Labels.SortedPairs }} • *{{ .Name }}:* {{ .Value }}
                {{ end }}
              {{ end }}
      
      - name: 'slack-info'
        slack_configs:
          - channel: '#alerts-info'
            send_resolved: true
            title: '[{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}] Info Alert'
            text: >-
              {{ range .Alerts }}
                *Alert:* {{ .Annotations.summary }}
                *Description:* {{ .Annotations.description }}
                *Severity:* {{ .Labels.severity }}
                *Details:*
                {{ range .Labels.SortedPairs }} • *{{ .Name }}:* {{ .Value }}
                {{ end }}
              {{ end }}

# Grafana configuration
grafana:
  # Enable Grafana
  enabled: true
  
  # Admin password
  adminPassword: admin
  
  # Resources for Grafana
  resources:
    limits:
      cpu: 300m
      memory: 512Mi
    requests:
      cpu: 100m
      memory: 128Mi
  
  # Persistence for Grafana
  persistence:
    enabled: true
    storageClassName: standard
    size: 10Gi
  
  # Ingress for Grafana
  ingress:
    enabled: true
    ingressClassName: nginx
    hosts:
      - grafana.sparkfund.com
    tls:
      - secretName: grafana-tls
        hosts:
          - grafana.sparkfund.com
  
  # Additional plugins for Grafana
  plugins:
    - grafana-piechart-panel
    - grafana-worldmap-panel
    - grafana-clock-panel
    - grafana-kubernetes-app
    - grafana-singlestat-panel
    - jdbranham-diagram-panel
    - natel-discrete-panel
    - vonage-status-panel
  
  # Additional data sources for Grafana
  additionalDataSources:
    - name: Loki
      type: loki
      url: http://loki-gateway.monitoring:80
      access: proxy
      isDefault: false
    - name: Tempo
      type: tempo
      url: http://tempo-query-frontend.monitoring:3100
      access: proxy
      isDefault: false
  
  # Dashboards configuration
  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
        - name: 'default'
          orgId: 1
          folder: ''
          type: file
          disableDeletion: false
          editable: true
          options:
            path: /var/lib/grafana/dashboards/default
        - name: 'kubernetes'
          orgId: 1
          folder: 'Kubernetes'
          type: file
          disableDeletion: false
          editable: true
          options:
            path: /var/lib/grafana/dashboards/kubernetes
        - name: 'istio'
          orgId: 1
          folder: 'Istio'
          type: file
          disableDeletion: false
          editable: true
          options:
            path: /var/lib/grafana/dashboards/istio
        - name: 'sparkfund'
          orgId: 1
          folder: 'SparkFund'
          type: file
          disableDeletion: false
          editable: true
          options:
            path: /var/lib/grafana/dashboards/sparkfund
  
  # Dashboards to import
  dashboards:
    default:
      node-exporter:
        gnetId: 1860
        revision: 22
        datasource: Prometheus
      kubernetes-cluster:
        gnetId: 7249
        revision: 1
        datasource: Prometheus
    kubernetes:
      kubernetes-api-server:
        gnetId: 12006
        revision: 1
        datasource: Prometheus
      kubernetes-coredns:
        gnetId: 7279
        revision: 1
        datasource: Prometheus
      kubernetes-resource-requests:
        gnetId: 6417
        revision: 1
        datasource: Prometheus
    istio:
      istio-mesh:
        gnetId: 7639
        revision: 1
        datasource: Prometheus
      istio-service:
        gnetId: 7636
        revision: 1
        datasource: Prometheus
      istio-workload:
        gnetId: 7630
        revision: 1
        datasource: Prometheus
    sparkfund:
      sparkfund-overview:
        url: https://raw.githubusercontent.com/adil-faiyaz98/sparkfund/main/deploy/grafana/dashboards/sparkfund-overview.json
      sparkfund-services:
        url: https://raw.githubusercontent.com/adil-faiyaz98/sparkfund/main/deploy/grafana/dashboards/sparkfund-services.json

# Node Exporter configuration
nodeExporter:
  # Enable Node Exporter
  enabled: true
  
  # Resources for Node Exporter
  resources:
    limits:
      cpu: 100m
      memory: 128Mi
    requests:
      cpu: 50m
      memory: 64Mi

# kube-state-metrics configuration
kubeStateMetrics:
  # Enable kube-state-metrics
  enabled: true
  
  # Resources for kube-state-metrics
  resources:
    limits:
      cpu: 100m
      memory: 128Mi
    requests:
      cpu: 50m
      memory: 64Mi

# Prometheus Adapter configuration
prometheusAdapter:
  # Enable Prometheus Adapter
  enabled: true
  
  # Resources for Prometheus Adapter
  resources:
    limits:
      cpu: 100m
      memory: 128Mi
    requests:
      cpu: 50m
      memory: 64Mi
  
  # Rules for Prometheus Adapter
  rules:
    default: true
    custom:
      - seriesQuery: '{__name__=~"^container_.*",container!="POD",namespace!="",pod!=""}'
        resources:
          overrides:
            namespace: {resource: "namespace"}
            pod: {resource: "pod"}
        name:
          matches: "^container_(.*)_seconds_total$"
          as: ""
        metricsQuery: 'sum(rate(<<.Series>>{<<.LabelMatchers>>}[5m])) by (<<.GroupBy>>)'
      - seriesQuery: '{__name__=~"^container_.*",container!="POD",namespace!="",pod!=""}'
        resources:
          overrides:
            namespace: {resource: "namespace"}
            pod: {resource: "pod"}
        name:
          matches: "^container_(.*)_total$"
          as: ""
        metricsQuery: 'sum(rate(<<.Series>>{<<.LabelMatchers>>}[5m])) by (<<.GroupBy>>)'
      - seriesQuery: '{__name__=~"^container_.*",container!="POD",namespace!="",pod!=""}'
        resources:
          overrides:
            namespace: {resource: "namespace"}
            pod: {resource: "pod"}
        name:
          matches: "^container_(.*)$"
          as: ""
        metricsQuery: 'sum(<<.Series>>{<<.LabelMatchers>>}) by (<<.GroupBy>>)'
      - seriesQuery: '{namespace!="",__name__!~"^container_.*"}'
        resources:
          template: "<<.Resource>>"
        name:
          matches: ""
          as: ""
        metricsQuery: 'sum(<<.Series>>{<<.LabelMatchers>>}) by (<<.GroupBy>>)'
